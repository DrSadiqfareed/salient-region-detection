# -*- coding: utf-8 -*-
"""salient_region_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bM6-x8OiIIOdTz7nA_LpwwU40rT3odqs
"""

import numpy as np
import cv2
from skimage.segmentation import slic
from skimage.color import rgb2lab
from sklearn.metrics.pairwise import euclidean_distances
from scipy.sparse.linalg import eigs
from scipy.ndimage import gaussian_filter

def superpixel_segmentation(image, n_segments=400, compactness=20):
    """Segment the image into superpixels using SLIC."""
    segments = slic(image, n_segments=n_segments, compactness=compactness, start_label=0)
    return segments

def compute_sparse_saliency(image, segments):
    """Compute sparse saliency based on superpixels and boundary priors."""
    h, w, _ = image.shape
    num_segments = segments.max() + 1
    saliency_map = np.zeros(num_segments)

    # Convert to LAB color space for better perceptual representation
    lab_image = rgb2lab(image)
    segment_means = np.array([
        np.mean(lab_image[segments == i], axis=0) for i in range(num_segments)
    ])

    # Boundary priors (edges are assumed to be background)
    boundary_segments = np.unique(
        np.concatenate([segments[0, :], segments[-1, :], segments[:, 0], segments[:, -1]])
    )
    boundary_mean = np.mean(segment_means[boundary_segments], axis=0)

    # Sparse saliency based on contrast with boundary segments
    for i in range(num_segments):
        saliency_map[i] = np.linalg.norm(segment_means[i] - boundary_mean)

    # Normalize saliency values
    saliency_map = (saliency_map - saliency_map.min()) / (saliency_map.max() - saliency_map.min())
    return saliency_map, segment_means

def compute_graph_based_ranking(saliency_map, segments, segment_means):
    """Compute graph-based ranking to refine saliency."""
    num_segments = segments.max() + 1
    graph_weights = euclidean_distances(segment_means, segment_means)

    # Normalize graph weights
    graph_weights = np.exp(-graph_weights / graph_weights.std())

    # Laplacian matrix
    degree_matrix = np.diag(graph_weights.sum(axis=1))
    laplacian = degree_matrix - graph_weights

    # Eigenvalue decomposition
    _, eig_vectors = eigs(laplacian, k=2, which='SM')
    refined_saliency = np.abs(eig_vectors[:, 1])
    refined_saliency = (refined_saliency - refined_saliency.min()) / (refined_saliency.max() - refined_saliency.min())

    return refined_saliency

def apply_bayesian_integration(sparse_saliency, graph_saliency):
    """Fuse sparse and graph-based saliency using Bayesian integration."""
    posterior = sparse_saliency * graph_saliency
    posterior /= posterior.max()  # Normalize
    return posterior

def create_final_saliency_map(posterior_saliency, segments):
    """Map saliency values back to the image."""
    final_map = np.zeros(segments.shape)
    for segment_id, saliency_value in enumerate(posterior_saliency):
        final_map[segments == segment_id] = saliency_value
    return final_map

# Main Pipeline
def salient_region_detection(image_path):
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Step 1: Superpixel Segmentation
    segments = superpixel_segmentation(image)

    # Step 2: Sparse Saliency
    sparse_saliency, segment_means = compute_sparse_saliency(image, segments)

    # Step 3: Graph-Based Ranking
    graph_saliency = compute_graph_based_ranking(sparse_saliency, segments, segment_means)

    # Step 4: Bayesian Integration
    posterior_saliency = apply_bayesian_integration(sparse_saliency, graph_saliency)

    # Step 5: Generate Final Saliency Map
    final_map = create_final_saliency_map(posterior_saliency, segments)

    return final_map

# Example Usage
image_path = "/content/download.jpg"  # Replace with your image path
final_saliency_map = salient_region_detection(image_path)

# Visualize Results
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.imshow(final_saliency_map, cmap='hot')
plt.title("Saliency Map")
plt.axis("off")
plt.show()